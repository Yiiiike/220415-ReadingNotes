{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出所有数据文件地址\n",
    "file_name_list = [\"subject_dystonia_hcc_area_lh.dat\",\n",
    "                  \"subject_dystonia_hcc_area_rh.dat\",\n",
    "                  \"subject_dystonia_hcc_curvind_lh.dat\",\n",
    "                  \"subject_dystonia_hcc_curvind_rh.dat\",\n",
    "                  \"subject_dystonia_hcc_foldind_lh.dat\",\n",
    "                  \"subject_dystonia_hcc_foldind_rh.dat\",\n",
    "                  \"subject_dystonia_hcc_gauscurv_lh.dat\",\n",
    "                  \"subject_dystonia_hcc_gauscurv_rh.dat\",\n",
    "                  \"subject_dystonia_hcc_meancurv_lh.dat\",\n",
    "                  \"subject_dystonia_hcc_meancurv_rh.dat\",\n",
    "                  \"subject_dystonia_hcc_Subcortical_volume_stats.txt\",\n",
    "                  \"subject_dystonia_hcc_thickness_lh.dat\",\n",
    "                  \"subject_dystonia_hcc_thickness_rh.dat\",\n",
    "                  \"subject_dystonia_hcc_thicknessstd_lh.dat\",\n",
    "                  \"subject_dystonia_hcc_thicknessstd_rh.dat\",\n",
    "                  \"subject_dystonia_hcc_volume_lh.dat\",\n",
    "                  \"subject_dystonia_hcc_volume_rh.dat\"]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "addr = \"./features/\"\n",
    "data = pd.read_table(addr + file_name_list[0])\n",
    "\n",
    "# 拼接所有数据\n",
    "for i in range(1, len(file_name_list)):\n",
    "    tmp = pd.read_table(addr + file_name_list[i])\n",
    "    data = pd.concat([data, tmp], axis=1)\n",
    "\n",
    "data.to_csv('./output_csv/data_step1_concat.csv', index=False)\n",
    "\n",
    "# 用数字替代类别信息：BPS->0, CD->1, HCC->2\n",
    "data_select = data\n",
    "tmp = []\n",
    "for a in data_select.iloc[:,0]:\n",
    "    if 'BPS' in a: tmp.append(0)\n",
    "    elif 'CD' in a: tmp.append(1)\n",
    "    else: tmp.append(2) \n",
    "data_select.iloc[:,0] = tmp\n",
    "data_select.rename(columns={'lh.aparc.area':'category'}, inplace=True)\n",
    "\n",
    "# 删除无关变量\n",
    "titles = data_select.columns\n",
    "drop_list = ['BrainSegVolNotVent','eTIV','Measure:volume','BrainSegVol','lhCortexVol','rhCortexVol',\n",
    "             'CortexVol','CerebralWhiteMatterVol','SubCortGrayVol','TotalGrayVol','SupraTentorialVol',\n",
    "             'SupraTentorialVolNotVent','MaskVol','BrainSegVol-to-eTIV','MaskVol-to-eTIV',\n",
    "             'SurfaceHoles','EstimatedTotalIntraCranialVol']\n",
    "for item in drop_list:\n",
    "    if item in titles: data_select.drop(item, axis=1, inplace=True)\n",
    "for item in titles:\n",
    "    if 'aparc' in item: data_select.drop(item, axis=1, inplace=True)\n",
    "\n",
    "# 对所有数据进行最大最小归一化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns_list = data_select.columns.tolist()\n",
    "data_Norm = data_select\n",
    "data_Norm[columns_list[1:]] = MinMaxScaler().fit_transform(data[columns_list[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 PCA降维方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行pca降维，连续两次\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 准备进行降维的数据，剔除目标值\n",
    "data_D_reduction = data_Norm.iloc[:, 1:]\n",
    "\n",
    "X_pca = PCA(n_components=10).fit_transform(data_D_reduction)\n",
    "X_pca2 = PCA(n_components=3).fit_transform(X_pca)\n",
    "\n",
    "# 划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = X_pca2 # X的类型无误\n",
    "# 将y的类型转为ndarray，同时需要y的dtype为int\n",
    "y = data_Norm.iloc[:, 0]\n",
    "y = y.to_numpy().astype(int) \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 PCA降维后的数据集分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 散点图矩阵\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# tmp1, tmp2 = pd.DataFrame(X), pd.DataFrame(y)\n",
    "# data_test_1 = pd.concat([tmp1, tmp2], axis=1)\n",
    "\n",
    "# data_test_1.columns = ['feature1', 'feature2', 'feature3', 'target']\n",
    "\n",
    "# sns.pairplot(data_test_1, hue='target')\n",
    "# plt.show()\n",
    "\n",
    "# # import seaborn as sns\n",
    "# # sns.pairplot(data_Norm, hue='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d散点图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分布图与箱线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# cate_name = ['BPS', 'CD', 'HCC']\n",
    "# auc_scores = []\n",
    "\n",
    "# # 模型训练\n",
    "# model = svm.SVC()\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "cate_name = ['BPS', 'CD', 'HCC']\n",
    "auc_scores = []\n",
    "\n",
    "# 模型训练\n",
    "model = svm.SVC()\n",
    "param_grid = {\n",
    "    'C': [1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10], \n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': [0.1, 1, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5)\n",
    "print(\"\\nCross-validation scores: \", cv_scores)\n",
    "print(\"Mean score: \", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_val)\n",
    "\n",
    "for class_label in range(3):\n",
    "    y_true = (y_val == class_label).astype(int)\n",
    "    y_pred = y_prob[:, class_label]\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"AUC for class {cate_name[class_label]}: {auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
